# Project Overview:

### Developed an automated data collection and processing pipeline to scrape daily retail prices of essential commodities from the Department of Consumer Affairs (Price Monitoring Division) for August and September 2023. The project efficiently transforms the collected data into Excel and CSV formats for further analysis.

# Key Features:

### 1) Utilized Selenium WebDriver for dynamic web scraping to handle website interactions and data extraction.
### 2) Employed libraries such as glob and xlwings for efficient data handling and conversion to Excel format.
### 3) Leveraged pandas for data manipulation and time and os libraries for task automation and file management.
### 4) Automated the conversion of Excel sheets into CSV format to facilitate seamless data analysis.

# Technologies and Tools:

### 1) Python: Core programming language.
### 2) Selenium WebDriver: For dynamic and interactive web scraping.
### 3) pandas: Data manipulation and analysis.
### 4) xlwings: Integration with Excel for data handling.
### 5) glob: File pattern matching for batch processing.
### 6) time and os: For automation and system operations.

# Impact:
### This project streamlined the data collection process, significantly reducing manual effort and increasing data accuracy for essential commodity price monitoring. The automated pipeline ensures timely data availability for analysts, enabling more informed decision-making based on up-to-date market information.
